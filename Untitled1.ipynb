{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37ba8640",
   "metadata": {},
   "source": [
    "# importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c7ca983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\new\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e7e6583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb88c21",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "685dea9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Link</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>تيرتل تري لابز للتقنيات الحيويه تحصل علي تمويل...</td>\n",
       "      <td>جاءت جوله التمويل التمهيديه الاولي للشركه بقيا...</td>\n",
       "      <td>https://ryadiybusiness.com/%d8%aa%d9%8a%d8%b1%...</td>\n",
       "      <td>ريادة أعمال</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>تعد دراسه الجدوي لمشروعك الناشء 6 عوامل اساسيه</td>\n",
       "      <td>تعد دراسه الجدوي متطلبا اساسيا لنجاح اي مشروع ...</td>\n",
       "      <td>https://ryadiybusiness.com/%d9%83%d9%8a%d9%81-...</td>\n",
       "      <td>ريادة أعمال</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>منح جاءزه نوبل الطب لاكتشاف مجال التهاب الكبد ...</td>\n",
       "      <td>وقالت لجنه نوبل للمره الاولي التاريخ يمكن الان...</td>\n",
       "      <td>https://arabic.sputniknews.com/science/2020100...</td>\n",
       "      <td>علوم وتكنولوجيا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>هيءه الغذاء والدواء الامريكيه لقاح مودرنا حقق ...</td>\n",
       "      <td>نشرت الوكاله وثاءق علي الانترنت اعدها موظفوها ...</td>\n",
       "      <td>https://arabic.sputniknews.com/world/202012151...</td>\n",
       "      <td>علوم وتكنولوجيا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>حظر بروتين الجهاز المناعي يساعد علي محاربه عدو...</td>\n",
       "      <td>دراسه حديثه قام فريق العلماء جونز هوبكنز ميديس...</td>\n",
       "      <td>https://arabic.rt.com//technology/1161864-%D8%...</td>\n",
       "      <td>علوم وتكنولوجيا</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  تيرتل تري لابز للتقنيات الحيويه تحصل علي تمويل...   \n",
       "1     تعد دراسه الجدوي لمشروعك الناشء 6 عوامل اساسيه   \n",
       "2  منح جاءزه نوبل الطب لاكتشاف مجال التهاب الكبد ...   \n",
       "3  هيءه الغذاء والدواء الامريكيه لقاح مودرنا حقق ...   \n",
       "4  حظر بروتين الجهاز المناعي يساعد علي محاربه عدو...   \n",
       "\n",
       "                                             Content  \\\n",
       "0  جاءت جوله التمويل التمهيديه الاولي للشركه بقيا...   \n",
       "1  تعد دراسه الجدوي متطلبا اساسيا لنجاح اي مشروع ...   \n",
       "2  وقالت لجنه نوبل للمره الاولي التاريخ يمكن الان...   \n",
       "3  نشرت الوكاله وثاءق علي الانترنت اعدها موظفوها ...   \n",
       "4  دراسه حديثه قام فريق العلماء جونز هوبكنز ميديس...   \n",
       "\n",
       "                                                Link         Category  \n",
       "0  https://ryadiybusiness.com/%d8%aa%d9%8a%d8%b1%...      ريادة أعمال  \n",
       "1  https://ryadiybusiness.com/%d9%83%d9%8a%d9%81-...      ريادة أعمال  \n",
       "2  https://arabic.sputniknews.com/science/2020100...  علوم وتكنولوجيا  \n",
       "3  https://arabic.sputniknews.com/world/202012151...  علوم وتكنولوجيا  \n",
       "4  https://arabic.rt.com//technology/1161864-%D8%...  علوم وتكنولوجيا  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"processed_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2558919a",
   "metadata": {},
   "source": [
    "# preprocessing on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1414ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Title',inplace=True,axis=1)\n",
    "data.drop('Link',inplace=True,axis=1)\n",
    "data.drop('Category',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da7ba5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Content    13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "503e73ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8386, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36f01c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    }
   ],
   "source": [
    "dupl = data[data.duplicated()]\n",
    "if len(dupl)>0:\n",
    "    data=data.drop_duplicates()\n",
    "    print(len(dupl))\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe16b3",
   "metadata": {},
   "source": [
    "# text normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2abb03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    if not isinstance(text, (str, bytes)):\n",
    "        # If input is not a string or bytes-like object, convert it to string\n",
    "        text = str(text)\n",
    "    \n",
    "    if text.startswith(\"ال\"):\n",
    "        text = text[2:]\n",
    "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"[ًٌٍَُِّْ]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab01756",
   "metadata": {},
   "source": [
    "# remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94b99eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_arabic_Remove_stop(words):\n",
    "    stop_words = set(stopwords.words('arabic'))\n",
    "    preprocessed_text=[]\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    preprocessed_text = words\n",
    "\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71427c83",
   "metadata": {},
   "source": [
    "# remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bbb6f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punctuation(words):\n",
    "    cleaned_words = [word for word in words if word not in string.punctuation]\n",
    "    return cleaned_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf62a11",
   "metadata": {},
   "source": [
    "# lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8ccbc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2996033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    out = remove_punctuation(words)\n",
    "    out = preprocess_arabic_Remove_stop(out)\n",
    "    out = lemma(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7603de32",
   "metadata": {},
   "source": [
    "# indexing using inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf5b6091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inverted_index(documents):\n",
    "    inverted_index = dict()\n",
    "    for doc_id, doc in enumerate(documents):\n",
    "        doc = normalize_arabic(doc)\n",
    "        terms = preprocess_text(doc)\n",
    "\n",
    "        for term in terms:\n",
    "            if term not in inverted_index:\n",
    "                inverted_index[term] = []\n",
    "            if doc_id not in inverted_index[term]:\n",
    "                inverted_index[term].append(doc_id)\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7488079",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = create_inverted_index(data['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d22a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81c6bd53",
   "metadata": {},
   "source": [
    "# retreiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96cb0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, inverted_index, documents):\n",
    "    query = normalize_arabic(query)\n",
    "    query = preprocess_text(query)\n",
    "    relevant_doc_ids = list(range(len(documents)))\n",
    "\n",
    "  \n",
    "    print(query)\n",
    "\n",
    "    for term in query:\n",
    "        relevant_docs = []\n",
    "        if term in inverted_index:\n",
    "            p1 = 0\n",
    "            p2 = 0\n",
    "            while p1 < len(relevant_doc_ids) and p2 < len(inverted_index[term]):\n",
    "                if relevant_doc_ids[p1] < inverted_index[term][p2]:\n",
    "                    p1 += 1\n",
    "                elif relevant_doc_ids[p1] > inverted_index[term][p2]:\n",
    "                    p2 += 1\n",
    "                else:\n",
    "                    relevant_docs.append(relevant_doc_ids[p1])\n",
    "                    p1 += 1\n",
    "                    p2 += 1\n",
    "            relevant_doc_ids = relevant_docs\n",
    "    return relevant_doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ed7b0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['جونز', 'هوبكنز']\n",
      "['جونز', 'هوبكنز']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4      دراسه حديثه قام فريق العلماء جونز هوبكنز ميديس...\n",
       "69     الان بدا توزيع لقاحات عديده اماكن مختلفه العال...\n",
       "221    تمكن فريق الباحثين مختبر الفيزياء التطبيقيه ال...\n",
       "702    ظل الزياده الكبيره تكاليف الامدادات والشحن وال...\n",
       "999    جاء دراسه جديده صدرت قبيل المنتدي العالمي الاو...\n",
       "Name: Content, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('جونز هوبكنز',inverted_index,data['Content'])\n",
    "res=data.iloc[search('جونز هوبكنز',inverted_index,data['Content'])].head(5)\n",
    "res.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae23ce0",
   "metadata": {},
   "source": [
    "# vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "548ec694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "vectorizer = TfidfVectorizer()\n",
    "def tf_idf(text):\n",
    "    doc = normalize_arabic(text)\n",
    "    terms = preprocess_text(doc)\n",
    "    terms_str = ' '.join(terms)\n",
    "    vectors = vectorizer.transform([terms_str])\n",
    "    return vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b73c496",
   "metadata": {},
   "source": [
    "# ranking by simalrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01007841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(query):\n",
    "    X = vectorizer.fit_transform(data['Content'])  \n",
    "    query_vector = tf_idf(query)\n",
    "    cosine_similarities = cosine_similarity(query_vector, X)\n",
    "    data['cosine_similarity'] = cosine_similarities[0]\n",
    "    df_sorted = data.sort_values(by='cosine_similarity', ascending=False)\n",
    "    similar_documents = df_sorted[df_sorted['cosine_similarity'] > 0.0]\n",
    "    similar_document_ids = similar_documents.iloc[:, 0]\n",
    "    return similar_document_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7998ba2f",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baac32cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['لسرطان']\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bisect\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from tkinter.filedialog import askopenfilename, askopenfilenames\n",
    "from tkinter import messagebox\n",
    "from PIL import ImageTk , Image\n",
    "import os\n",
    "import ast\n",
    "root=Tk()\n",
    "root.geometry('750x600')\n",
    "root.resizable(False,False)\n",
    "root.title('IR')\n",
    "root.config(background='#ffffff')\n",
    "img=Image.open(\"D://src_ir.png\")\n",
    "img_resize=img.resize((10,10))\n",
    "icon=ImageTk.PhotoImage(img_resize)\n",
    "root.iconphoto(False,icon)\n",
    "docs=StringVar()\n",
    "ranked_docs=StringVar()\n",
    "query=StringVar()\n",
    "def ranking():\n",
    "    query_str = query.get()\n",
    "    cosine_similarities = cosine(query_str)\n",
    "    ranked_docs.set(cosine_similarities)\n",
    "\n",
    "def search2():\n",
    "    query_str = query.get()\n",
    "    res1=data.iloc[search(query_str,inverted_index,data['Content'])].head(5)\n",
    "    docs.set(res1.iloc[:, 0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "image=Image.open('D://src2_ir.png')\n",
    "image=image.resize((750,250))\n",
    "photo2=ImageTk.PhotoImage(image)\n",
    "Label(root,image=photo2).place(x=0,y=0)\n",
    "\n",
    "search_entry=Entry(root,width=70,borderwidth=2,font=(\"calibri\",18),justify='right',textvariable=query)\n",
    "search_entry.place(x=60,y=220)\n",
    "\n",
    "frame1=LabelFrame(root,bg=\"#ffffff\",text=\"Searching algorthim\",width=300,height=400,font=(\"calibri\", 14))\n",
    "frame1.place(x=10,y=270)\n",
    "\n",
    "Label(frame1, bg=\"#ffffff\", fg=\"#000000\", textvariable=docs, font=(\"calibri\", 8),justify='right').place(x=10, y=10)\n",
    "\n",
    "frame2=LabelFrame(root,bg=\"#ffffff\",width=300,height=400,text=\"Ranking algorthim\",font=(\"calibri\", 14))\n",
    "frame2.place(x=430,y=270)\n",
    "\n",
    "Label(frame2, bg=\"#ffffff\", fg=\"#000000\", textvariable=ranked_docs, font=(\"calibri\", 8),justify='right').place(x=10, y=10)\n",
    "\n",
    "Button(frame2,width=17,height=2,text=\"Ranking\",bg='#cce7ec',command=ranking, font=(\"calibri\", 12)).place(x=70,y=240)\n",
    "Button(frame1,width=17,height=2,text=\"search\",bg='#cce7ec',command=search2, font=(\"calibri\", 12)).place(x=70,y=240)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db5f79a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
